<h2> Deep Learning Implementations </h2>

The task 1 here is only a basic implementations of very basic tasks of implementing Stochastic Gradient Descent by using first a vanilla implementation on a non-convex function created during the implementation and juxtaposing to least squares fitting. 

The task 2 is an ablation study of using different activation functions on a similar architecture, a convolutional neural network followed by a K-Folds implemetation all done from scratch in pytorch. 

<h2> Note: all implementations are in PyTorch </h2>
